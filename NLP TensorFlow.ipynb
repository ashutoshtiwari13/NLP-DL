{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TensorFlow used to express a numeric computation as a graph\n",
    "#graph nodes are operations which have any number of inputs\n",
    "#graph edges are tensors which flow between nodes\n",
    "#h(output)=ReLU(Wx+b)\n",
    "# variables are stateful nodes which output their current value here W and b\n",
    "# pLaceholders are nodes whose value is fed in at excecution time(inputs,labels)\n",
    "# MatMul,Add,Relu nodes in the graph formed as backbone of COde\n",
    "\n",
    "#code formation\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "b=tf.Variable(tf.zeros((100,)))\n",
    "W=tf.Variable(tf.random_uniform((784,100),-1,1))\n",
    "\n",
    "x= tf.placeholder(tf.float32,(100,784))\n",
    "h=tf.nn.relu(tf.matmul(x,W)+b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the graph i sformed by the above code\n",
    "#this graph is to be placed in an execution environment by creating a session\n",
    "# sess.run(fetches,feeds)\n",
    "# Fetches- list of graph nodes. return the outputs of these nodes\n",
    "#feeds- dictionary mapping from graph noes to concreate values. Specifies the value of each graph node given in the dictionary\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "sess.run(h,{x:np.random.random(100,784)})\n",
    "\n",
    "\n",
    "#now we train the model\n",
    "prediction=tf.nn.softmax(...) #output of the neural network\n",
    "label=tf.placeholder(tf.float32,[100,10])\n",
    "\n",
    " cross_entropy=-tf.reduce_sum(label* tf.log(prediction),axis=1)\n",
    "#above gives the negative log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now as a next step we an optimizer ,here Gradient Decent but can be Many say ,ADAM\n",
    "train_step=tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "#here 0.5 is the learning rate\n",
    "sess=tf.session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "#running the loop for the batch size\n",
    "for i in range(1000):\n",
    "    batch_x,batch_label=data.next_batch()\n",
    "    sess.run(train_step,feed_dict={x:batch_x,label:batch_label})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaring of shared variables\n",
    "tf.variable_scope()\n",
    "tf.get_variable()\n",
    "\n",
    "with tf.variable_scope(\"foo\"):\n",
    "    v=tf.get_variable(\"v\",shape=[1]) #v.name==\"foo/v:0\"\n",
    "with tf.variable_scope(\"foo\",reuse=True):\n",
    "    v1=tf.get_variable(\"v\") #v.name==\"foo/v:0\"\n",
    "with tf.variable_scope(\"foo\",reuse=False):\n",
    "    v1=tf.get_variable(\"v\") #CRASH\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
